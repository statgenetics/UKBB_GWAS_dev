{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Principal component analysis\n",
    "\n",
    "The intention of this notebook is to generate the PCA analysis and plots for the exomed samples 200K.\n",
    "\n",
    "Steps to generate a PCA include removing related individuals, pruning variants in linkage disequilibrium (LD), and excluding outlier samples that can suggest poor genotyping quality or distant relatedness (also restrict to individuals of homogeneous ancestry).\n",
    "\n",
    "Pitfalls\n",
    "1. Some of the PCs may capture LD structure rather than population structure (decrease in power to detect associations in these regions of high LD)\n",
    "2. When projecting a new study dataset to the PCA space computed from a reference dataset: projected PCs are shrunk toward 0 in the new dataset \n",
    "3.  PC scores may capture outliers that are due to family structure, population structure or other reasons; it might be beneficial to detect and remove these individuals to maximize the population structure captured by PCA (in the case of removing a few outliers) or to restrict analyses to genetically homogeneous samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run PCA.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  filter_samples\n",
      "  filter\n",
      "  pca\n",
      "  flashpca\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd VAL (as path, required)\n",
      "                        the output directory for generated files\n",
      "  --genoFile  paths\n",
      "\n",
      "                        Plink binary files\n",
      "  --famFile VAL (as path, required)\n",
      "                        The fam file associated to the bed files\n",
      "  --database VAL (as path, required)\n",
      "                        The database to extract info from\n",
      "  --ethnia-prefix VAL (as str, required)\n",
      "                        The prefix for the output files\n",
      "  --phenoFile  path(f'{cwd}/cache/{famFile:bn}.{ethnia_prefix}.pheno')\n",
      "\n",
      "                        The phenotypic file\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --numThreads 1 (as int)\n",
      "                        Number of threads\n",
      "  --eigensoft-module '\\nmodule load EIGENSOFT/7.2.1-foss-2018b\\necho \"Module Eigensoft v.7.2.1 loaded\"\\n{cmd}\\n'\n",
      "                        Load Eigensoft module from cluster\n",
      "  --container-lmm 'statisticalgenetics/lmm:1.7'\n",
      "                        Software container option\n",
      "\n",
      "Sections\n",
      "  filter_samples:       Filter individuals from ancestries different than\n",
      "                        British, Irish, Other white background, prefer not to\n",
      "                        answer, do not know\n",
      "    Workflow Options:\n",
      "      --select-ethnia  (as list)\n",
      "  filter_1:             Filter SNPs with MAF>1% for PCA analysis, select\n",
      "                        individuals and merge bed into one file\n",
      "    Workflow Options:\n",
      "      --maf-filter 0.01 (as float)\n",
      "      --geno-filter 0.01 (as float)\n",
      "                        Maximum missingess per-variant\n",
      "      --mind-filter 0.02 (as float)\n",
      "                        Maximum missingness per-sample\n",
      "      --hwe-filter 0.0 (as float)\n",
      "  filter_2:             Merge all the .bed files into one bed file for input to\n",
      "                        eigensoft\n",
      "  filter_3:             LD prunning window=50, shift-window every 5 SNPS, r2=0.5\n",
      "    Workflow Options:\n",
      "      --window 50 (as int)\n",
      "      --shift 5 (as int)\n",
      "      --r2 0.5 (as float)\n",
      "  pca_1:                Run pca analysis using Eigenstrat: the program suports\n",
      "                        plink files here called PACKEDPED format smartpca.perl:\n",
      "                        run PCA on input genotype data (calls smartpca)\n",
      "    Workflow Options:\n",
      "      --k VAL (as int, required)\n",
      "                        Number of Principal Components to output\n",
      "      --maxiter 0 (as int)\n",
      "                        Maximum number of iterations for outlier removal.\n",
      "                        Default 0 turns off outlier removal\n",
      "      --topk 10 (as int)\n",
      "                        Number of principal components along which to remove\n",
      "                        outliers during each outlier removal iteration. Default\n",
      "                        is 10\n",
      "      --sigma 6 (as int)\n",
      "                        Number of standard deviations which an individual must\n",
      "                        exceed, along one of topk top principal components, in\n",
      "                        order to be removed as an outlier. Default is 6\n",
      "  flashpca:             Run PCA analysis using flashpca\n",
      "    Workflow Options:\n",
      "      --k VAL (as int, required)\n",
      "                        Number of Principal Components to output. Default is 10\n",
      "      --trait-name VAL (as str, required)\n",
      "                        Name of the trait in the phenoFile (format FID, IID,\n",
      "                        father, mother,trait )\n",
      "      --stand binom2\n",
      "                        How to standardize X before PCA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sos run PCA.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## PCA analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# Plink binary files\n",
    "parameter: genoFile = paths\n",
    "# The fam file associated to the bed files\n",
    "parameter: famFile = path \n",
    "# The database to extract info from\n",
    "parameter: database = path\n",
    "# The prefix for the output files\n",
    "parameter: ethnia_prefix = str\n",
    "# The phenotypic file\n",
    "parameter: phenoFile = path(f'{cwd}/cache/{famFile:bn}.{ethnia_prefix}.pheno')\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Number of threads\n",
    "parameter: numThreads = 1\n",
    "# Merge data\n",
    "parameter: merge = True\n",
    "# Load Eigensoft module from cluster\n",
    "parameter: eigensoft_module = '''\n",
    "module load EIGENSOFT/7.2.1-foss-2018b\n",
    "echo \"Module Eigensoft v.7.2.1 loaded\"\n",
    "{cmd}\n",
    "'''\n",
    "# Software container option\n",
    "parameter: container_lmm = 'statisticalgenetics/lmm:1.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Filter individuals depending on their ancestry\n",
    "[filter_samples]\n",
    "parameter: select_ethnia = [ ]\n",
    "output: f'{cwd}/cache/{famFile:bn}.{ethnia_prefix}', phenoFile\n",
    "task: trunk_workers = 1, walltime = '10h', mem = '40G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: container=container_lmm, expand= \"${ }\", stderr = f'{_output[0]:nn}.stderr', stdout = f'{_output[0]:nn}.stdout'\n",
    "    #Load libraries\n",
    "    library('dplyr')\n",
    "    # This database is the one from June 2020 and contains a subset of variables with the PCs\n",
    "    fam <- read.table(${famFile:r}, sep=' ', header=F)\n",
    "    colnames(fam) <- c(\"FID\",\"IID\",\"fatherID\", \"motherID\", \"sex\", \"phenotype\")\n",
    "    cat(\"There are\",nrow(fam),\"individuals with exomes.\\n\")\n",
    "    bd <- read.table(${database:r}, sep=\"\\t\", header=T)\n",
    "    cat(\"The size of the full database is\",dim(bd),\".\\n\")\n",
    "    # Assign individual ID column to bd f.eid\n",
    "    names(bd)[1] <- \"IID\"\n",
    "    # Select the 200K individuals with exomes from the full db\n",
    "    exomed_IID <- bd[bd$IID %in% fam$IID,]\n",
    "    cat(\"The number of selected individuals is\",nrow(exomed_IID),\".\\n\")\n",
    "    # Filter db based on ethnicity variable\n",
    "    ethnicity <- exomed_IID %>%\n",
    "          select(IID, starts_with(\"f.21000\"))\n",
    "    ethnicity <- ethnicity %>%\n",
    "          mutate_all(na_if,-3) %>%\n",
    "          mutate_all(na_if,-1)\n",
    "    # Function to extract all the available answers for 3 visits and put them in one list\n",
    "    f<-function(x){\n",
    "      visit<-c()\n",
    "      for (i in 2:4){\n",
    "        if (!is.na(x[i]))\n",
    "        {visit<-c(visit,x[i])}\n",
    "      }\n",
    "      if(is.null(visit)){visit=-99}\n",
    "      else{visit=as.numeric(visit)}\n",
    "      return (visit)\n",
    "    }\n",
    "\n",
    "    # Apply the above function and remove NAs\n",
    "    ethnicity$visit<-apply(ethnicity, 1, f)\n",
    "    # Filter out individuals wih missing values in ethnicity: 212 ind total\n",
    "    ethnicity <- ethnicity %>%\n",
    "      filter(!is.na(visit))\n",
    "    cat(\"There are\",nrow(ethnicity),\"individuals without missing values for ethnicity.\\n\")\n",
    "    # Identify the unique available codings in f.21000\n",
    "    code<-union(union(unique(ethnicity$f.21000.0.0),unique(ethnicity$f.21000.1.0)),unique(ethnicity$f.21000.2.0))\n",
    "    # Codes to keep white individuals\n",
    "    #useful_code<-c(1001,1002,1003,1,-3,-1)\n",
    "    useful_code<-c(${','.join(['%s ' % x for x in select_ethnia if x is not None])})\n",
    "    # the rest that donâ€™t have the combinations above can be set as NA\n",
    "    useless_code<-code[!code %in% useful_code] \n",
    "    useless_code<-useless_code[-which(is.na(useless_code))] # remove NA here in the vector\n",
    "    # Function to get the final code for ethnicity\n",
    "    f<-function(x){\n",
    "      l=length(unique(x$visit))\n",
    "      if (l==1){ # only one value available\n",
    "        result=unique(x$visit)\n",
    "      }\n",
    "      else{ # more then one value available\n",
    "        l=length(x$visit)\n",
    "        for (i in 1:l){\n",
    "          if (x$visit[i] %in% useless_code){result=8000; break} # inconsistent ones with conbination not wanted\n",
    "          else {result=9000} # inconsistent ones with right conbination\n",
    "        }\n",
    "      }\n",
    "      return(result)\n",
    "    }\n",
    "\n",
    "    # Apply the above function and remove NAs\n",
    "    ethnicity$new_ethnicity<-apply(ethnicity, 1, f)\n",
    "    # Filter by NA presence\n",
    "    ethnicity_noNA<-ethnicity %>%\n",
    "      filter(!is.na(new_ethnicity))\n",
    "    cat(\"There are\",nrow(ethnicity_noNA),\"individuals consistent for f.21000.\\n\")\n",
    "    ethnicity_isNA <- ethnicity %>%\n",
    "      filter(is.na(new_ethnicity))\n",
    "    cat(\"There are\",nrow(ethnicity_isNA),\"individuals inconsistent for f.21000.\\n\")\n",
    "    # keep only certain individuals\n",
    "    ${ethnia_prefix} <- ethnicity_noNA %>%\n",
    "        filter(new_ethnicity %in% useful_code) %>%\n",
    "        mutate(FID = IID) %>%\n",
    "        select(FID,IID)\n",
    "    cat(\"After excluding ethnic backgrounds different than  ${ethnia_prefix}, the number of individuals is\",nrow(${ethnia_prefix}),\".\\n\")\n",
    "    # Write the selected individuals to a txt file\n",
    "    write.table(${ethnia_prefix},${_output[0]:r}, sep=\"\\t\", row.names=FALSE, col.names=F)\n",
    "    # Create the phenotype file\n",
    "    pheno <- ethnicity_noNA %>%\n",
    "        filter(new_ethnicity %in% useful_code) %>%\n",
    "        mutate(ethnicity = new_ethnicity) %>%\n",
    "        select(IID,ethnicity)\n",
    "    # Merge the two data frames\n",
    "    famfile <-merge(fam, pheno, by=\"IID\", all=FALSE)\n",
    "    cat(\"The famfile has \",nrow(famfile),\"individuals.\\n\")\n",
    "    write.table(famfile,${_output[1]:r}, sep=\"\\t\", row.names=FALSE, col.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Filter SNPs with MAF>1% for PCA analysis, select individuals and merge bed into one file\n",
    "[filter_1]\n",
    "parameter: maf_filter = 0.01\n",
    "#Maximum missingess per-variant\n",
    "parameter: geno_filter = 0.01\n",
    "#Maximum missingness per-sample\n",
    "parameter: mind_filter = 0.02\n",
    "parameter: hwe_filter = 0.0\n",
    "input: genoFile, group_by=1\n",
    "output: f'{cwd}/cache/{_input:bn}.filtered.bed'\n",
    "task: trunk_workers = 1, walltime = '10h', mem = '30G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    plink2 \\\n",
    "      --bfile ${_input:n} \\\n",
    "      ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} ${('--geno %s' % geno_filter) if geno_filter > 0 else ''} ${('--hwe %s' % hwe_filter) if hwe_filter > 0 else ''} ${('--mind %s' % mind_filter) if mind_filter > 0 else ''} \\\n",
    "      --keep ${cwd}/cache/${famFile:bn}.${ethnia_prefix} \\\n",
    "      --make-bed \\\n",
    "      --threads ${numThreads} \\\n",
    "      --out ${_output:n} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge all the .bed files into one bed file for input to eigensoft\n",
    "[filter_2:skip=not merge]\n",
    "input: group_by = 'all'\n",
    "output: bfile_merge = f'{cwd}/cache/{famFile:bn}.filtered.merged.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    echo -e ${' '.join([str(x)[:-4] for x in _input[1:]])} | sed 's/ /\\n/g' > ${_output:n}.merge_list\n",
    "    plink \\\n",
    "    --bfile ${_input[0]:n} \\\n",
    "    --merge-list ${_output:n}.merge_list \\\n",
    "    --make-bed \\\n",
    "    --out ${_output:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# LD prunning window=50, shift-window every 10 SNPS, r2=0.1\n",
    "[filter_3]\n",
    "parameter: window = 50\n",
    "parameter: shift = 10\n",
    "parameter: r2 = 0.1\n",
    "output: f'{cwd}/cache/{famFile:bn}.filtered.merged.prune.in', f'{cwd}/{famFile:bn}.filtered.merged.prune.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    plink \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --indep-pairwise ${window} ${shift} ${r2}  \\\n",
    "    --out ${_output[0]:nn} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory 48000\n",
    "    \n",
    "    plink \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --extract ${_output[0]} \\\n",
    "    --make-bed \\\n",
    "    --out ${_output[1]:n} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run pca analysis using Eigenstrat: the program suports plink files here called PACKEDPED format\n",
    "# smartpca.perl: run PCA on input genotype data (calls smartpca)\n",
    "[smartpca]\n",
    "# Number of Principal Components to output\n",
    "parameter: k = int\n",
    "# Maximum number of iterations for outlier removal. Default 0 turns off outlier removal\n",
    "parameter: maxiter = 0\n",
    "# Number of principal components along which to remove outliers during each outlier removal iteration. Default is 10\n",
    "parameter: topk = 10\n",
    "# Number of standard deviations which an individual must exceed, along one of topk top principal components, in order to be removed as an outlier. Default is 6\n",
    "parameter: sigma = 6\n",
    "input: f'{cwd}/{famFile:bn}.filtered.merged.bed'\n",
    "output: f'{cwd}/{_input:bn}.parfile' ,  f'{cwd}/{_input:bn}.pca'\n",
    "task: trunk_workers = 1, walltime = '24h', mem = '80G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',  template = '{cmd}' if executable('smartpca.perl').target_exists() else eigensoft_module\n",
    "  #Create the parfile\n",
    "  set -e\n",
    "  echo -e \"genotypename: ${_input}\" >> ${_output[0]}\n",
    "  echo -e \"snpname: ${_input:n}.bim\" >> ${_output[0]}\n",
    "  echo -e \"indivname: ${_input:n}.eigenstrat.fam\" >> ${_output[0]}\n",
    "  echo -e \"outputformat: EIGENSTRAT\" >> ${_output[0]}\n",
    "  echo -e \"fastmode: YES\" >> ${_output[0]}\n",
    "  echo -e \"genotypeoutname: ${_input:n}.geno\" >> ${_output[0]}\n",
    "  echo -e \"snpoutname: ${_input:n}.snp\" >> ${_output[0]}\n",
    "  echo -e \"indivoutname: ${_input:n}.ind\" >> ${_output[0]}\n",
    "  echo -e \"evectoutname: ${_input:n}.evectout\" >> ${_output[0]}\n",
    "  echo -e \"evaloutname: ${_input:n}.evalout\" >> ${_output[0]} \n",
    "  echo -e \"numoutevec: ${k}\" >> ${_output[0]} \n",
    "  echo -e \"numoutlieriter: ${maxiter}\" >> ${_output[0]} \n",
    "  echo -e \"numoutlierevec: ${topk}\" >> ${_output[0]} \n",
    "  echo -e \"outliersigmathresh: ${sigma}\" >> ${_output[0]} \n",
    "  \n",
    "\n",
    "bash: expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',  template = '{cmd}' if executable('smartpca.perl').target_exists() else eigensoft_module\n",
    "   convertf -p ${_output[0]}\n",
    "   #smartpca -p ${_output[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run PCA analysis using flashpca\n",
    "[flashpca]\n",
    "# Number of Principal Components to output. Default is 10\n",
    "parameter: k = int\n",
    "# Name of the trait in the phenoFile (format FID, IID, father, mother,trait )\n",
    "parameter: trait_name = str\n",
    "# How to standardize X before PCA\n",
    "parameter: stand = \"binom2\"\n",
    "depends: phenoFile\n",
    "input: f'{cwd}/{famFile:bn}.filtered.merged.prune.bed'\n",
    "output: f'{cwd}/{_input[0]:bn}.pca',\n",
    "        f'{cwd}/{_input[0]:bn}.pc1vpc2.png',\n",
    "        f'{cwd}/{_input[0]:bn}.pc3vpc4.png',\n",
    "        f'{cwd}/{_input[0]:bn}.pc5vpc6.png' \n",
    "task: trunk_workers = 1, walltime = '10h', mem = '30G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    # Load required libraries\n",
    "    library(dplyr)\n",
    "    library(ggplot2)\n",
    "    library(flashpcaR)\n",
    "    # Read the PLINK binary files\n",
    "    fn <- ${_input:nr}\n",
    "    # Do the PCA computation\n",
    "    f <- flashpca(fn, ndim=${k}, stand=\"${stand}\", do_loadings=TRUE, check_geno=TRUE)\n",
    "    # Save the generated matrices to files\n",
    "    write.table(f$values,'${_output[0]:n}.values', sep=\" \", row.names=FALSE, col.names=FALSE) \n",
    "    write.table(f$vectors,'${_output[0]:n}.vectors', sep=\" \", row.names=TRUE, col.names=FALSE)\n",
    "    write.table(f$projection,'${_output[0]:n}.projection', sep=\" \", row.names=TRUE, col.names=FALSE)\n",
    "    write.table(f$loadings,'${_output[0]:n}.loadings', sep=\" \", row.names=FALSE, col.names=FALSE)\n",
    "    write.table(f$scale,'${_output[0]:n}.scale', sep=\" \", row.names=FALSE, col.names=FALSE)\n",
    "    # Use the projection file to generate plot\n",
    "    pca <- read.table('${_output[0]:n}.projection', sep=\" \")\n",
    "    colnames(pca) <- c(\"ID\",\"PC1\",\"PC2\",\"PC3\",\"PC4\",\"PC5\",\"PC6\",\"PC7\",\"PC8\",\"PC9\",\"PC10\")\n",
    "    pca$IID <- sapply(strsplit(as.character(pca$ID),':'), \"[\", 1)\n",
    "    # Read fam file with phenotypes\n",
    "    pheno <- read.table(${phenoFile:r}, sep=\"\\t\" )\n",
    "    colnames(pheno) <- c(\"FID\", \"IID\", \"father\", \"mother\",\"sex\", \"pheno\", \"${trait_name}\")\n",
    "    pca_final <-merge(pheno, pca, by=\"IID\", all=FALSE)\n",
    "\n",
    "    write.table(pca_final,${_output[0]:r}, sep=\"\\t\", quote=FALSE, row.names=FALSE, col.names=TRUE)\n",
    "  \n",
    "    png('${_output[1]}', width = 6, height = 4, unit='in', res=300)\n",
    "    ggplot(pca_final, aes(x=PC1, y=PC2)) + geom_point(aes(color=${trait_name}, shape=${trait_name}), size=2) + labs(title=\"PC1 vs PC2 exomed subset ${ethnia_prefix}\",x=\"PC1\", y=\"PC2\") + theme_classic()\n",
    "    dev.off()\n",
    "  \n",
    "    png('${_output[2]}', width = 6, height = 4, unit='in', res=300)\n",
    "    ggplot(pca_final, aes(x=PC3, y=PC4)) + geom_point(aes(color=${trait_name}, shape=${trait_name}), size=2) + labs(title=\"PC3 vs PC4 exomed subset ${ethnia_prefix}\", x=\"PC3\", y=\"PC4\") + theme_classic()\n",
    "    dev.off()\n",
    "    \n",
    "    png('${_output[3]}', width = 6, height = 4, unit='in', res=300)\n",
    "    ggplot(pca_final, aes(x=PC5, y=PC6)) + geom_point(aes(color=${trait_name}, shape=${trait_name}), size=2) + labs(title=\"P5 vs PC6 exomed subset ${ethnia_prefix}\",x=\"PC5\", y=\"PC6\") + theme_classic()\n",
    "    dev.off()           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "calysto_bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.21.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
